{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ce831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LalO8uUyrrEh",
    "outputId": "6880e1c5-5103-4a1c-f2f3-93d90219aba9"
   },
   "outputs": [],
   "source": [
    "# Google Drive bağlantısını kur ve veri seti klasörünü kullanıcıdan al\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Kullanıcıdan veri klasörünün adını girmesini iste (Örn: MyDrive/Dataset)\n",
    "data_dir = input(\"Lütfen veri setinin bulunduğu Drive klasör yolunu girin (Örn: MyDrive/YSA): \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1468379",
   "metadata": {
    "id": "k91zZ93yrzBR"
   },
   "source": [
    "Google Drive Bağlantısı ve Gerekli Kütüphanelerin Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc87a0",
   "metadata": {
    "id": "trX9KWZErhqF"
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri içe aktaralım\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Veri dengesizliği olması durumunda over-sampling için\n",
    "try:\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "except ImportError:\n",
    "    !pip install imbalanced-learn\n",
    "    from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b169e7",
   "metadata": {
    "id": "q1BXeYePr8MU"
   },
   "source": [
    "Veri Yükleme ve Görüntüleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8729af7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yeskpxJr6w0",
    "outputId": "ed2605ba-01bd-4a67-83d0-90892750343c"
   },
   "outputs": [],
   "source": [
    "# Veri setlerini yükleyelim (dinamik yol)\n",
    "try:\n",
    "    train_metadata = pd.read_csv(f'/content/drive/{data_dir}/Metadata_Train.csv')\n",
    "    test_metadata = pd.read_csv(f'/content/drive/{data_dir}/Metadata_Test.csv')\n",
    "    \n",
    "    print(\"Eğitim veri seti ilk 5 satır:\")\n",
    "    print(train_metadata.head())\n",
    "    print(\"\\nTest veri seti ilk 5 satır:\")\n",
    "    print(test_metadata.head())\n",
    "\n",
    "    # Veri seti hakkında genel bilgiler\n",
    "    print(\"\\nEğitim veri seti bilgileri:\")\n",
    "    print(train_metadata.info())\n",
    "    print(\"\\nEksik veriler:\")\n",
    "    print(train_metadata.isnull().sum())\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: Dosya bulunamadı, lütfen dosya yolunu kontrol edin.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120ec21",
   "metadata": {
    "id": "TncQaPq2sDd6"
   },
   "source": [
    "Ses Dosyalarını Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23273b4",
   "metadata": {
    "id": "VqDjehCDLy1b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "def load_audio_files_in_batches(base_path, batch_size=50):\n",
    "    files = os.listdir(base_path)\n",
    "    error_files = []\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i+batch_size]\n",
    "        audio_data, sample_rates = [], []\n",
    "        for file in tqdm(batch_files, desc=f\"Batch {i//batch_size + 1}\"):\n",
    "            file_path = os.path.join(base_path, file)\n",
    "            try:\n",
    "                audio, sr = librosa.load(file_path, sr=22050)\n",
    "                audio_data.append(audio)\n",
    "                sample_rates.append(sr)\n",
    "            except Exception as e:\n",
    "                error_files.append((file, str(e)))\n",
    "        yield audio_data, sample_rates, batch_files, error_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5374c",
   "metadata": {
    "id": "97LcO90KIrYB"
   },
   "outputs": [],
   "source": [
    "def load_audio_files(base_path):\n",
    "    files = [f for f in os.listdir(base_path) if f.endswith(('.wav', '.mp3', '.flac'))]  # Yalnızca ses dosyalarını seç\n",
    "    audio_data, sample_rates, error_files = [], [], []\n",
    "    for file in tqdm(files, desc=\"Ses Dosyaları Yükleniyor\"):\n",
    "        file_path = os.path.join(base_path, file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=22050)\n",
    "            audio_data.append(audio)\n",
    "            sample_rates.append(sr)\n",
    "        except Exception as e:\n",
    "            error_files.append((file, str(e)))\n",
    "    return audio_data, sample_rates, files, error_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf3c51",
   "metadata": {
    "id": "G1iO6M2SLUwp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_audio_files(base_path):\n",
    "    files = os.listdir(base_path)\n",
    "    audio_data, sample_rates, error_files = [], [], []\n",
    "    for file in tqdm(files, desc=\"Ses Dosyaları Yükleniyor\"):\n",
    "        file_path = os.path.join(base_path, file)\n",
    "        try:\n",
    "            if file.endswith('.npy'):  # NumPy dosyası için özel işlem\n",
    "                audio = np.load(file_path)\n",
    "                sr = 22050  # NumPy dosyasının örnekleme oranı bilinmiyorsa varsayılan kullanılır\n",
    "            else:  # Ses dosyaları için Librosa\n",
    "                audio, sr = librosa.load(file_path, sr=22050)\n",
    "            audio_data.append(audio)\n",
    "            sample_rates.append(sr)\n",
    "        except Exception as e:\n",
    "            error_files.append((file, str(e)))\n",
    "    return audio_data, sample_rates, files, error_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3587ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOy30cJHr7AY",
    "outputId": "0004e293-4937-42ed-c43e-7fa741bce19d"
   },
   "outputs": [],
   "source": [
    "def load_audio_files(base_path):\n",
    "    files = [f for f in os.listdir(base_path) if f.endswith(('.wav', '.mp3', '.flac'))]  # Yalnızca ses dosyalarını seç\n",
    "    audio_data, sample_rates, error_files = [], [], []\n",
    "    for file in tqdm(files, desc=\"Ses Dosyaları Yükleniyor\"):\n",
    "        file_path = os.path.join(base_path, file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=22050)\n",
    "            audio_data.append(audio)\n",
    "            sample_rates.append(sr)\n",
    "        except Exception as e:\n",
    "            error_files.append((file, str(e)))\n",
    "    return audio_data, sample_rates, files, error_files\n",
    "\n",
    "train_base_path = '/content/drive/MyDrive/YSA/Train_submission/Train_submission'\n",
    "all_audio_data, all_sample_rates, files, error_files = load_audio_files(train_base_path)\n",
    "\n",
    "if error_files:\n",
    "    print(\"\\nYüklenemeyen dosyalar:\")\n",
    "    for file, error in error_files:\n",
    "        print(f\"Dosya: {file}, Hata: {error}\")\n",
    "else:\n",
    "    print(\"\\nTüm dosyalar başarıyla yüklendi!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30897b0",
   "metadata": {
    "id": "vPq3WEJ6sMAf"
   },
   "source": [
    "Özellik Çıkarma ve Etiketleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545607c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlRnxo77r7D1",
    "outputId": "3552539a-93eb-417f-9622-ab7c417eda5a"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "def extract_features_and_labels(audio_data, sample_rates, files):\n",
    "    features, labels = [], []\n",
    "    for idx, (audio, sr) in enumerate(zip(audio_data, sample_rates)):\n",
    "        try:\n",
    "            features.append(extract_features(audio, sr))\n",
    "            if \"Guitar\" in files[idx]:\n",
    "              labels.append(\"Guitar\")\n",
    "            elif \"Drum\" in files[idx]:\n",
    "                labels.append(\"Drum\")\n",
    "            elif \"Violin\" in files[idx]:\n",
    "                labels.append(\"Violin\")\n",
    "            elif \"Piano\" in files[idx]:\n",
    "                labels.append(\"Piano\")\n",
    "            else:\n",
    "                labels.append(\"Unknown\")\n",
    "        except Exception as e:\n",
    "            print(f\"Özellik çıkarma sırasında hata: {files[idx]}, Hata: {e}\")\n",
    "    return pd.DataFrame(features), labels\n",
    "\n",
    "def extract_features(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "    features = np.concatenate([\n",
    "        np.mean(mfccs.T, axis=0),\n",
    "        np.mean(chroma.T, axis=0),\n",
    "        np.mean(spectral_contrast.T, axis=0)\n",
    "    ])\n",
    "    return features\n",
    "\n",
    "\n",
    "features_df, labels = extract_features_and_labels(all_audio_data, all_sample_rates, files)\n",
    "features_df['Label'] = labels\n",
    "print(f\"Toplam veri: {len(features_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c3ec2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "YJDmysab_1gh",
    "outputId": "3a6744f6-d7a6-45d0-eae8-028fdfa86a52"
   },
   "outputs": [],
   "source": [
    "# Spektrogram görselleştirme fonksiyonu\n",
    "def plot_spectrogram(audio, sr):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Spektrogram görselleştirme\n",
    "plot_spectrogram(all_audio_data[0], all_sample_rates[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4811f44",
   "metadata": {
    "id": "4pi0iVrYsTh5"
   },
   "source": [
    "Veri Artırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fca7bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdnNCzAjsTQn",
    "outputId": "21650ce9-4545-4341-eda8-661352bb4faf"
   },
   "outputs": [],
   "source": [
    "def add_noise(audio, noise_level=0.005):\n",
    "    noise = np.random.normal(0, noise_level, audio.shape)\n",
    "    return audio + noise\n",
    "\n",
    "def shift_audio(audio, shift_max=0.2):\n",
    "    shift = int(np.random.uniform(-shift_max, shift_max) * len(audio))\n",
    "    return np.roll(audio, shift)\n",
    "\n",
    "def change_speed_scipy(audio, speed_factor):\n",
    "    try:\n",
    "        new_length = int(len(audio) / speed_factor)\n",
    "        return librosa.resample(audio, orig_sr=len(audio), target_sr=new_length)\n",
    "    except Exception as e:\n",
    "        return audio\n",
    "\n",
    "def augment_audio_data(audio_data, labels):\n",
    "    augmented_data, augmented_labels = [], []\n",
    "    for audio, label in zip(audio_data, labels):\n",
    "        augmented_data.extend([\n",
    "            audio,\n",
    "            add_noise(audio),\n",
    "            shift_audio(audio),\n",
    "            change_speed_scipy(audio, 1.2),\n",
    "            change_speed_scipy(audio, 0.8)\n",
    "        ])\n",
    "        augmented_labels.extend([label] * 5)\n",
    "    return augmented_data, augmented_labels\n",
    "\n",
    "augmented_data, augmented_labels = augment_audio_data(all_audio_data, labels)\n",
    "print(f\"Artırılmış veri sayısı: {len(augmented_data)}\")\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(features_df.iloc[:, :-1], features_df['Label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2ee44",
   "metadata": {
    "id": "Uhze5_lWsZsm"
   },
   "source": [
    "Veri Dengeleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66e4a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uWG9cGWsSlu",
    "outputId": "f3659268-f8f1-4622-af52-af45ee8cbf56"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(features_df.iloc[:, :-1], features_df['Label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Etiketleri encode et ve one-hot dönüştür\n",
    "label_encoder = LabelEncoder()\n",
    "y_resampled_encoded = label_encoder.fit_transform(y_resampled)  # Etiketleri encode et\n",
    "y_train = tf.keras.utils.to_categorical(label_encoder.transform(y_train), num_classes=len(label_encoder.classes_))\n",
    "y_test = tf.keras.utils.to_categorical(label_encoder.transform(y_test), num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b96b9",
   "metadata": {
    "id": "Bc9jqb8dsenK"
   },
   "source": [
    "Model Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168e2b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "tmWxnVZPsSvm",
    "outputId": "75c1b036-7267-4e2b-f7c2-12c1f7f82918"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=(input_shape,), activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  # Çıkış katmanı\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Sınıf sayısını belirleme\n",
    "num_classes = y_train.shape[1]  # One-hot encoded olduğu için sütun sayısı sınıf sayısını verir\n",
    "\n",
    "# Model oluşturma\n",
    "model = create_cnn_model(X_train.shape[1], num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4a05c",
   "metadata": {
    "id": "_QVL-L5EslDf"
   },
   "source": [
    "Modeli Eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385123e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bjV_cXYskxw",
    "outputId": "164d03fa-eb2c-4efa-a833-170f3691bda5"
   },
   "outputs": [],
   "source": [
    "# Öğrenme oranı zamanlayıcısı\n",
    "def scheduler(epoch, lr):\n",
    "    return lr if epoch < 10 else float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "# Callbacks tanımlama\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "checkpointer = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Model eğitimi\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[lr_scheduler, checkpointer]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1eace",
   "metadata": {
    "id": "y4VzsvAtsrRs"
   },
   "source": [
    "Eğitim Geçmişini Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6259f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "1YZepF7Nsiyd",
    "outputId": "1cdb271b-895b-4c8d-b308-489f782f7c1c"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
    "    plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
    "    plt.title('Doğruluk')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
    "    plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
    "    plt.title('Kayıp')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f172319a",
   "metadata": {
    "id": "eAmeFSiBsvxy"
   },
   "source": [
    "Yeni Ses Dosyasını Tahmin Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4696f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "qAX1iScGbkpG",
    "outputId": "36053977-4421-4ec4-d50e-5ed8bc0265d6"
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin yüklenmesi\n",
    "!pip install torch torchvision torchaudio -q\n",
    "\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Ses dosyasını yükleme ve çalma\n",
    "audio_path = '/content/drive/MyDrive/YSA/Test_submission/Test_submission/darbuka-drum-percussion-64018.wav'\n",
    "\n",
    "# Torchaudio ile ses dosyasını yükle\n",
    "audio, rate = torchaudio.load(audio_path)\n",
    "\n",
    "# Ses bilgilerini ekrana yazdır\n",
    "print(f\"Ses Şekli: {audio.shape}, Örnekleme Oranı: {rate}\")\n",
    "\n",
    "# Ses dosyasını çal\n",
    "print(\"Ses çalınıyor...\")\n",
    "Audio(audio.numpy().flatten(), rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d0fa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDoBY19yY-Um",
    "outputId": "acae758a-8b59-4edf-d850-345f24c877c1"
   },
   "outputs": [],
   "source": [
    "# Yeni bir ses dosyasını tahmin etme\n",
    "test_audio, test_sr = librosa.load('/content/drive/MyDrive/YSA/Test_submission/Test_submission/darbuka-drum-percussion-64018.wav', sr=22050)\n",
    "test_features = extract_features(test_audio, test_sr).reshape(1, -1)\n",
    "\n",
    "prediction = model.predict(test_features)\n",
    "predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "print(f\"Tahmin Edilen Sınıf: {predicted_label[0]}\")\n",
    "\n",
    "# Test seti üzerinde modeli değerlendirme\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Seti Doğruluk: {test_accuracy:.4f}\")\n",
    "print(f\"Test Seti Kayıp: {test_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2872b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "4G8vaj39NG7N",
    "outputId": "151d2b98-5781-4ac0-c2ea-e81c0a69b4fb"
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin yüklenmesi\n",
    "!pip install torch torchvision torchaudio -q\n",
    "\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Ses dosyasını yükleme ve çalma\n",
    "audio_path = '/content/drive/MyDrive/YSA/Test_submission/Test_submission/ROOM_room6_MUS_pachelbel_DEV_lg.wav'\n",
    "\n",
    "# Torchaudio ile ses dosyasını yükle\n",
    "audio, rate = torchaudio.load(audio_path)\n",
    "\n",
    "# Ses bilgilerini ekrana yazdır\n",
    "print(f\"Ses Şekli: {audio.shape}, Örnekleme Oranı: {rate}\")\n",
    "\n",
    "# Ses dosyasını çal\n",
    "print(\"Ses çalınıyor...\")\n",
    "Audio(audio.numpy().flatten(), rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87639195",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZYPzIg5MsE2",
    "outputId": "0859e6e6-14c7-44cd-f417-c72c67b4debc"
   },
   "outputs": [],
   "source": [
    "# Yeni bir ses dosyasını tahmin etme\n",
    "test_audio, test_sr = librosa.load('/content/drive/MyDrive/YSA/Test_submission/Test_submission/ROOM_room6_MUS_pachelbel_DEV_lg.wav', sr=22050)\n",
    "test_features = extract_features(test_audio, test_sr).reshape(1, -1)\n",
    "\n",
    "prediction = model.predict(test_features)\n",
    "predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "print(f\"Tahmin Edilen Sınıf: {predicted_label[0]}\")\n",
    "\n",
    "# Test seti üzerinde modeli değerlendirme\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Seti Doğruluk: {test_accuracy:.4f}\")\n",
    "print(f\"Test Seti Kayıp: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65438960",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvLDQ6KxO_dU",
    "outputId": "0b7630bd-e788-498e-c012-b742fa52d476"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Test seti tahminleri\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Tahmin edilen sınıflar\n",
    "y_test_classes = np.argmax(y_test, axis=1)  # Gerçek sınıflar\n",
    "\n",
    "# Performans raporu\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "# Karışıklık matrisi\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Karışıklık Matrisi:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a29db8",
   "metadata": {
    "id": "FwNBmnLb1D3S"
   },
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
